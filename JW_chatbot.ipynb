{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JW_chatbot.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOWJHywVmFPkesoBXTGL4Yx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaewonLee0217/JW_chatbot/blob/main/JW_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIONZ7HosAD6"
      },
      "source": [
        "import json \r\n",
        "import numpy as np \r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0la99nWsL84"
      },
      "source": [
        "with open('intents.json') as file:\r\n",
        "  data = json.load(file)\r\n",
        "  #데이터 구조는 패턴, 리스폰스, 태그로 구성되어 있고, \r\n",
        "\r\n",
        "  training_sentences = [] # 실제 어구 \r\n",
        "  training_labels = [] #태그 정보들 \r\n",
        "  labels = [] # 이 문장이 인사인지 도움인지 뭐를 뜻하는 지 태그 정보 \r\n",
        "  responses = [] # 패턴에 대한 반응\r\n",
        "\r\n",
        "\r\n",
        "#data proprecessing -> 각 리스트에 정보 분배 \r\n",
        "for intent in data['intents']:\r\n",
        "  for pattern in intent['patterns']:\r\n",
        "    training_sentences.append(pattern)\r\n",
        "    training_labels.append(intent['tag'])\r\n",
        "  responses.append(intent['responses'])\r\n",
        "\r\n",
        "\r\n",
        "# 라벨 리스트에 태그 정보들 기록 \r\n",
        "  if intent['tag'] not in labels:\r\n",
        "    labels.append(intent['tag'])\r\n",
        "\r\n",
        "#라벨 리스트에 담은 길이가 클래스의 총 개수로 정해준다.\r\n",
        "num_classes = len(labels)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xCRpwWDtEAy"
      },
      "source": [
        "#인코딩 실행 sklearn의 전처리 라이브러리 불러오서 각 패턴에 대한 태그들,\r\n",
        "# 뭐라뭐라 말했을 떄 그 말에 대한 단어들을 모아둔 training_labels 에서 인코더를 fit 시키고 \r\n",
        "# 그것을 가주고 숫자 형태로 transforming 시켜 준다. \r\n",
        "lbl_encoder = LabelEncoder()\r\n",
        "lbl_encoder.fit(training_labels)\r\n",
        "training_labels = lbl_encoder.transform(training_labels)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyKE4lnEBvR4",
        "outputId": "aaef70b4-c05e-4b5f-c2dd-73d6c5c17701"
      },
      "source": [
        "training_labels"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 4, 4, 4, 3, 3, 3, 7, 7, 7, 7, 0, 0, 0, 6, 6, 6, 5, 5, 5, 5,\n",
              "       5, 5, 5, 2, 2, 2, 2, 2, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMWR43QjtZDG"
      },
      "source": [
        "vocab_size = 1000\r\n",
        "embedding_dim = 16\r\n",
        "max_len = 20\r\n",
        "oov_token = \"<OOV>\"\r\n",
        "\r\n",
        "#tokenizer는 텐서플로우의 keras라이브러리 꺼 사용. \r\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\r\n",
        "#여기서 문장에서 각 토큰 들 짤라주고 \r\n",
        "tokenizer.fit_on_texts(training_sentences)\r\n",
        "\r\n",
        "#짜른 토큰들을 word to index화 시킨다. \r\n",
        "word_index = tokenizer.word_index\r\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\r\n",
        "\r\n",
        "# 그럼 sequence에는 각 단어 문장의 단어마다 숫자로 표현되어 있지만 길이가 \r\n",
        "# 서로 다르므로 제로 패딩을 통해서 각 문장마다 길이 동일하게 만들어주고 트레이닝을 진행해야 한다\r\n",
        "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)\r\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbQbFKQltbnn",
        "outputId": "8132f9ee-68a5-4e49-e4ac-a23c5a20c358"
      },
      "source": [
        "#모델 훈련\r\n",
        "#모델을 먼저 텐서플로우 케라스 모델에서 세퀀셜가져오고\r\n",
        "\r\n",
        "\r\n",
        "#keras.layer 라이브러리에서 임베딩함수로 인풋이 들어갈 부분을 만들어준다. \r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\r\n",
        "model.add(GlobalAveragePooling1D())\r\n",
        "model.add(Dense(16, activation='relu'))\r\n",
        "model.add(Dense(16, activation='relu'))\r\n",
        "model.add(Dense(num_classes, activation='softmax'))\r\n",
        "\r\n",
        "model.compile(loss='sparse_categorical_crossentropy', \r\n",
        "              optimizer='adam', metrics=['accuracy'])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 20, 16)            16000     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 8)                 136       \n",
            "=================================================================\n",
            "Total params: 16,680\n",
            "Trainable params: 16,680\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDmuB7Hww7al",
        "outputId": "e8ef811f-f480-4e9b-afb6-cd05971704e3"
      },
      "source": [
        "epochs = 490\r\n",
        "history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0787 - accuracy: 0.1225\n",
            "Epoch 2/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.0776 - accuracy: 0.1225\n",
            "Epoch 3/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0768 - accuracy: 0.2449\n",
            "Epoch 4/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.0762 - accuracy: 0.2756\n",
            "Epoch 5/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.0755 - accuracy: 0.3368\n",
            "Epoch 6/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0750 - accuracy: 0.2756\n",
            "Epoch 7/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0744 - accuracy: 0.2449\n",
            "Epoch 8/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0739 - accuracy: 0.2143\n",
            "Epoch 9/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0734 - accuracy: 0.2652\n",
            "Epoch 10/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0723 - accuracy: 0.3368\n",
            "Epoch 11/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0719 - accuracy: 0.2143\n",
            "Epoch 12/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0716 - accuracy: 0.2039\n",
            "Epoch 13/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0711 - accuracy: 0.2039\n",
            "Epoch 14/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0704 - accuracy: 0.2143\n",
            "Epoch 15/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0699 - accuracy: 0.2039\n",
            "Epoch 16/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0691 - accuracy: 0.2143\n",
            "Epoch 17/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0684 - accuracy: 0.2143\n",
            "Epoch 18/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0676 - accuracy: 0.2143\n",
            "Epoch 19/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0669 - accuracy: 0.2039\n",
            "Epoch 20/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0655 - accuracy: 0.2143\n",
            "Epoch 21/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0646 - accuracy: 0.2143\n",
            "Epoch 22/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0647 - accuracy: 0.2039\n",
            "Epoch 23/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0641 - accuracy: 0.2039\n",
            "Epoch 24/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0627 - accuracy: 0.2143\n",
            "Epoch 25/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0626 - accuracy: 0.2039\n",
            "Epoch 26/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0615 - accuracy: 0.2143\n",
            "Epoch 27/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0612 - accuracy: 0.2039\n",
            "Epoch 28/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0603 - accuracy: 0.2039\n",
            "Epoch 29/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.0580 - accuracy: 0.2143\n",
            "Epoch 30/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0575 - accuracy: 0.2143\n",
            "Epoch 31/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0566 - accuracy: 0.2143\n",
            "Epoch 32/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0547 - accuracy: 0.2143\n",
            "Epoch 33/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.0550 - accuracy: 0.2143\n",
            "Epoch 34/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0545 - accuracy: 0.2143\n",
            "Epoch 35/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0550 - accuracy: 0.2039\n",
            "Epoch 36/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0531 - accuracy: 0.2143\n",
            "Epoch 37/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0530 - accuracy: 0.2143\n",
            "Epoch 38/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0532 - accuracy: 0.2039\n",
            "Epoch 39/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0500 - accuracy: 0.2143\n",
            "Epoch 40/490\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.0508 - accuracy: 0.2143\n",
            "Epoch 41/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.0480 - accuracy: 0.2143\n",
            "Epoch 42/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0500 - accuracy: 0.2143\n",
            "Epoch 43/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0495 - accuracy: 0.2143\n",
            "Epoch 44/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0476 - accuracy: 0.2143\n",
            "Epoch 45/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0487 - accuracy: 0.2143\n",
            "Epoch 46/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0473 - accuracy: 0.2143\n",
            "Epoch 47/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0464 - accuracy: 0.2143\n",
            "Epoch 48/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0475 - accuracy: 0.2143\n",
            "Epoch 49/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0473 - accuracy: 0.2143\n",
            "Epoch 50/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0468 - accuracy: 0.2143\n",
            "Epoch 51/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0464 - accuracy: 0.2143\n",
            "Epoch 52/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0452 - accuracy: 0.2143\n",
            "Epoch 53/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0456 - accuracy: 0.2143\n",
            "Epoch 54/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0452 - accuracy: 0.2143\n",
            "Epoch 55/490\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.0455 - accuracy: 0.2039\n",
            "Epoch 56/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0448 - accuracy: 0.2039\n",
            "Epoch 57/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0399 - accuracy: 0.2143\n",
            "Epoch 58/490\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 2.0424 - accuracy: 0.2143\n",
            "Epoch 59/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0404 - accuracy: 0.2143\n",
            "Epoch 60/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0410 - accuracy: 0.2143\n",
            "Epoch 61/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0370 - accuracy: 0.2143\n",
            "Epoch 62/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0379 - accuracy: 0.2143\n",
            "Epoch 63/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0362 - accuracy: 0.2143\n",
            "Epoch 64/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0393 - accuracy: 0.2143\n",
            "Epoch 65/490\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.0393 - accuracy: 0.2143\n",
            "Epoch 66/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0358 - accuracy: 0.2143\n",
            "Epoch 67/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.0386 - accuracy: 0.2143\n",
            "Epoch 68/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.0385 - accuracy: 0.2143\n",
            "Epoch 69/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0361 - accuracy: 0.2143\n",
            "Epoch 70/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0357 - accuracy: 0.2143\n",
            "Epoch 71/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0376 - accuracy: 0.2143\n",
            "Epoch 72/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0375 - accuracy: 0.2143\n",
            "Epoch 73/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0356 - accuracy: 0.2143\n",
            "Epoch 74/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0380 - accuracy: 0.2039\n",
            "Epoch 75/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0376 - accuracy: 0.2039\n",
            "Epoch 76/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0333 - accuracy: 0.2143\n",
            "Epoch 77/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0360 - accuracy: 0.2039\n",
            "Epoch 78/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0352 - accuracy: 0.2039\n",
            "Epoch 79/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0344 - accuracy: 0.2039\n",
            "Epoch 80/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0312 - accuracy: 0.2143\n",
            "Epoch 81/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.0296 - accuracy: 0.2143\n",
            "Epoch 82/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.0306 - accuracy: 0.2143\n",
            "Epoch 83/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.0277 - accuracy: 0.2143\n",
            "Epoch 84/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0264 - accuracy: 0.2143\n",
            "Epoch 85/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0271 - accuracy: 0.2143\n",
            "Epoch 86/490\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.0267 - accuracy: 0.2143\n",
            "Epoch 87/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0275 - accuracy: 0.2039\n",
            "Epoch 88/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.0236 - accuracy: 0.2143\n",
            "Epoch 89/490\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.0220 - accuracy: 0.2143\n",
            "Epoch 90/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.0213 - accuracy: 0.2143\n",
            "Epoch 91/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0201 - accuracy: 0.2143\n",
            "Epoch 92/490\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.0236 - accuracy: 0.2039\n",
            "Epoch 93/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0228 - accuracy: 0.2039\n",
            "Epoch 94/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0165 - accuracy: 0.2143\n",
            "Epoch 95/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0159 - accuracy: 0.2143\n",
            "Epoch 96/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0180 - accuracy: 0.2143\n",
            "Epoch 97/490\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.0178 - accuracy: 0.2143\n",
            "Epoch 98/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0137 - accuracy: 0.2143\n",
            "Epoch 99/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0187 - accuracy: 0.2039\n",
            "Epoch 100/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0141 - accuracy: 0.2143\n",
            "Epoch 101/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0153 - accuracy: 0.2143\n",
            "Epoch 102/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0145 - accuracy: 0.2143\n",
            "Epoch 103/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.0118 - accuracy: 0.2143\n",
            "Epoch 104/490\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.0128 - accuracy: 0.2143\n",
            "Epoch 105/490\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.0121 - accuracy: 0.2143\n",
            "Epoch 106/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0089 - accuracy: 0.2143\n",
            "Epoch 107/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0071 - accuracy: 0.2143\n",
            "Epoch 108/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0123 - accuracy: 0.2039\n",
            "Epoch 109/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0074 - accuracy: 0.2143\n",
            "Epoch 110/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0051 - accuracy: 0.2143\n",
            "Epoch 111/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.0104 - accuracy: 0.2039\n",
            "Epoch 112/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0073 - accuracy: 0.2143\n",
            "Epoch 113/490\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.0045 - accuracy: 0.2143\n",
            "Epoch 114/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0082 - accuracy: 0.2039\n",
            "Epoch 115/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.0073 - accuracy: 0.2039\n",
            "Epoch 116/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0062 - accuracy: 0.2039\n",
            "Epoch 117/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0049 - accuracy: 0.2039\n",
            "Epoch 118/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0008 - accuracy: 0.2143\n",
            "Epoch 119/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9981 - accuracy: 0.2143\n",
            "Epoch 120/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9950 - accuracy: 0.2143\n",
            "Epoch 121/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9994 - accuracy: 0.2039\n",
            "Epoch 122/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9920 - accuracy: 0.2143\n",
            "Epoch 123/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9923 - accuracy: 0.2143\n",
            "Epoch 124/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.9892 - accuracy: 0.2143\n",
            "Epoch 125/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9876 - accuracy: 0.2143\n",
            "Epoch 126/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9887 - accuracy: 0.2143\n",
            "Epoch 127/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9869 - accuracy: 0.2143\n",
            "Epoch 128/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9870 - accuracy: 0.2143\n",
            "Epoch 129/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.9830 - accuracy: 0.2143\n",
            "Epoch 130/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9812 - accuracy: 0.2143\n",
            "Epoch 131/490\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.9824 - accuracy: 0.2143\n",
            "Epoch 132/490\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.9817 - accuracy: 0.2143\n",
            "Epoch 133/490\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.9810 - accuracy: 0.2143\n",
            "Epoch 134/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9811 - accuracy: 0.2143\n",
            "Epoch 135/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9804 - accuracy: 0.2143\n",
            "Epoch 136/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9833 - accuracy: 0.2039\n",
            "Epoch 137/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9745 - accuracy: 0.2143\n",
            "Epoch 138/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9742 - accuracy: 0.2143\n",
            "Epoch 139/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9732 - accuracy: 0.2143\n",
            "Epoch 140/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9712 - accuracy: 0.2143\n",
            "Epoch 141/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9723 - accuracy: 0.2143\n",
            "Epoch 142/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.9776 - accuracy: 0.2039\n",
            "Epoch 143/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9729 - accuracy: 0.2143\n",
            "Epoch 144/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.9716 - accuracy: 0.2143\n",
            "Epoch 145/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9665 - accuracy: 0.2143\n",
            "Epoch 146/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9725 - accuracy: 0.2039\n",
            "Epoch 147/490\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.9629 - accuracy: 0.2143\n",
            "Epoch 148/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9658 - accuracy: 0.2143\n",
            "Epoch 149/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9645 - accuracy: 0.2143\n",
            "Epoch 150/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9636 - accuracy: 0.2143\n",
            "Epoch 151/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9622 - accuracy: 0.2143\n",
            "Epoch 152/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9589 - accuracy: 0.2143\n",
            "Epoch 153/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9636 - accuracy: 0.2039\n",
            "Epoch 154/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9537 - accuracy: 0.2143\n",
            "Epoch 155/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9566 - accuracy: 0.2143\n",
            "Epoch 156/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9505 - accuracy: 0.2143\n",
            "Epoch 157/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9522 - accuracy: 0.2143\n",
            "Epoch 158/490\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.9571 - accuracy: 0.2039\n",
            "Epoch 159/490\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.9509 - accuracy: 0.2143\n",
            "Epoch 160/490\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.9542 - accuracy: 0.2039\n",
            "Epoch 161/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9450 - accuracy: 0.2143\n",
            "Epoch 162/490\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 1.9511 - accuracy: 0.2039\n",
            "Epoch 163/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9493 - accuracy: 0.2039\n",
            "Epoch 164/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.9405 - accuracy: 0.2143\n",
            "Epoch 165/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9407 - accuracy: 0.2143\n",
            "Epoch 166/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9385 - accuracy: 0.2143\n",
            "Epoch 167/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9354 - accuracy: 0.2143\n",
            "Epoch 168/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9342 - accuracy: 0.2143\n",
            "Epoch 169/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9292 - accuracy: 0.2143\n",
            "Epoch 170/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9305 - accuracy: 0.2143\n",
            "Epoch 171/490\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.9353 - accuracy: 0.2039\n",
            "Epoch 172/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9245 - accuracy: 0.2143\n",
            "Epoch 173/490\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.9320 - accuracy: 0.2039\n",
            "Epoch 174/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9249 - accuracy: 0.2143\n",
            "Epoch 175/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9227 - accuracy: 0.2143\n",
            "Epoch 176/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9200 - accuracy: 0.2143\n",
            "Epoch 177/490\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.9171 - accuracy: 0.2143\n",
            "Epoch 178/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9150 - accuracy: 0.2143\n",
            "Epoch 179/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9088 - accuracy: 0.2143\n",
            "Epoch 180/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9097 - accuracy: 0.2143\n",
            "Epoch 181/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9175 - accuracy: 0.2039\n",
            "Epoch 182/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9099 - accuracy: 0.2143\n",
            "Epoch 183/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9084 - accuracy: 0.2143\n",
            "Epoch 184/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9122 - accuracy: 0.2039\n",
            "Epoch 185/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9040 - accuracy: 0.2143\n",
            "Epoch 186/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9004 - accuracy: 0.2143\n",
            "Epoch 187/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9010 - accuracy: 0.2143\n",
            "Epoch 188/490\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.8967 - accuracy: 0.2143\n",
            "Epoch 189/490\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.8985 - accuracy: 0.2143\n",
            "Epoch 190/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.9027 - accuracy: 0.2039\n",
            "Epoch 191/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.8938 - accuracy: 0.2143\n",
            "Epoch 192/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.8923 - accuracy: 0.2143\n",
            "Epoch 193/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.8909 - accuracy: 0.2143\n",
            "Epoch 194/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8966 - accuracy: 0.2039\n",
            "Epoch 195/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8836 - accuracy: 0.2143\n",
            "Epoch 196/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8842 - accuracy: 0.2143\n",
            "Epoch 197/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8786 - accuracy: 0.2143\n",
            "Epoch 198/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8849 - accuracy: 0.2143\n",
            "Epoch 199/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8884 - accuracy: 0.2039\n",
            "Epoch 200/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.8848 - accuracy: 0.2039\n",
            "Epoch 201/490\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.8788 - accuracy: 0.2143\n",
            "Epoch 202/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.8716 - accuracy: 0.2143\n",
            "Epoch 203/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8753 - accuracy: 0.2143\n",
            "Epoch 204/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.8689 - accuracy: 0.2143\n",
            "Epoch 205/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8659 - accuracy: 0.2143\n",
            "Epoch 206/490\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.8718 - accuracy: 0.2143\n",
            "Epoch 207/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.8639 - accuracy: 0.2143\n",
            "Epoch 208/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.8671 - accuracy: 0.2143\n",
            "Epoch 209/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8706 - accuracy: 0.2039\n",
            "Epoch 210/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8588 - accuracy: 0.2143\n",
            "Epoch 211/490\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.8621 - accuracy: 0.2143\n",
            "Epoch 212/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8667 - accuracy: 0.2039\n",
            "Epoch 213/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.8552 - accuracy: 0.2143\n",
            "Epoch 214/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.8496 - accuracy: 0.2756\n",
            "Epoch 215/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.8541 - accuracy: 0.3062\n",
            "Epoch 216/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8516 - accuracy: 0.2958\n",
            "Epoch 217/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8450 - accuracy: 0.3062\n",
            "Epoch 218/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8425 - accuracy: 0.3368\n",
            "Epoch 219/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8470 - accuracy: 0.3368\n",
            "Epoch 220/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8391 - accuracy: 0.3368\n",
            "Epoch 221/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8381 - accuracy: 0.3368\n",
            "Epoch 222/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.8487 - accuracy: 0.3264\n",
            "Epoch 223/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8362 - accuracy: 0.3368\n",
            "Epoch 224/490\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.8392 - accuracy: 0.3368\n",
            "Epoch 225/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8362 - accuracy: 0.3368\n",
            "Epoch 226/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8311 - accuracy: 0.3368\n",
            "Epoch 227/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8340 - accuracy: 0.3264\n",
            "Epoch 228/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8313 - accuracy: 0.3368\n",
            "Epoch 229/490\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.8297 - accuracy: 0.3368\n",
            "Epoch 230/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8287 - accuracy: 0.3368\n",
            "Epoch 231/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8271 - accuracy: 0.3368\n",
            "Epoch 232/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.8211 - accuracy: 0.3368\n",
            "Epoch 233/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8191 - accuracy: 0.3368\n",
            "Epoch 234/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8180 - accuracy: 0.3368\n",
            "Epoch 235/490\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.8152 - accuracy: 0.3368\n",
            "Epoch 236/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.8213 - accuracy: 0.3368\n",
            "Epoch 237/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.8174 - accuracy: 0.3368\n",
            "Epoch 238/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8221 - accuracy: 0.3264\n",
            "Epoch 239/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.8146 - accuracy: 0.3368\n",
            "Epoch 240/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.8141 - accuracy: 0.3368\n",
            "Epoch 241/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.8076 - accuracy: 0.3368\n",
            "Epoch 242/490\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.8147 - accuracy: 0.3264\n",
            "Epoch 243/490\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.8051 - accuracy: 0.3368\n",
            "Epoch 244/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.8026 - accuracy: 0.3368\n",
            "Epoch 245/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.8025 - accuracy: 0.3264\n",
            "Epoch 246/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.7880 - accuracy: 0.3368\n",
            "Epoch 247/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.7879 - accuracy: 0.3368\n",
            "Epoch 248/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.7898 - accuracy: 0.3264\n",
            "Epoch 249/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7867 - accuracy: 0.3264\n",
            "Epoch 250/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7746 - accuracy: 0.3368\n",
            "Epoch 251/490\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.7800 - accuracy: 0.3264\n",
            "Epoch 252/490\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.7674 - accuracy: 0.3368\n",
            "Epoch 253/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.7755 - accuracy: 0.3264\n",
            "Epoch 254/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.7623 - accuracy: 0.3368\n",
            "Epoch 255/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7643 - accuracy: 0.3264\n",
            "Epoch 256/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7516 - accuracy: 0.3368\n",
            "Epoch 257/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7494 - accuracy: 0.3368\n",
            "Epoch 258/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7558 - accuracy: 0.3264\n",
            "Epoch 259/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7513 - accuracy: 0.3264\n",
            "Epoch 260/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7372 - accuracy: 0.3368\n",
            "Epoch 261/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7299 - accuracy: 0.3368\n",
            "Epoch 262/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7293 - accuracy: 0.3368\n",
            "Epoch 263/490\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.7344 - accuracy: 0.3264\n",
            "Epoch 264/490\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.7247 - accuracy: 0.3368\n",
            "Epoch 265/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7283 - accuracy: 0.3264\n",
            "Epoch 266/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7180 - accuracy: 0.3368\n",
            "Epoch 267/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.7114 - accuracy: 0.3368\n",
            "Epoch 268/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7114 - accuracy: 0.3368\n",
            "Epoch 269/490\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.7040 - accuracy: 0.3368\n",
            "Epoch 270/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6992 - accuracy: 0.3368\n",
            "Epoch 271/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6959 - accuracy: 0.3368\n",
            "Epoch 272/490\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.6947 - accuracy: 0.3368\n",
            "Epoch 273/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6913 - accuracy: 0.3368\n",
            "Epoch 274/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6890 - accuracy: 0.3368\n",
            "Epoch 275/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6870 - accuracy: 0.3368\n",
            "Epoch 276/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6819 - accuracy: 0.3368\n",
            "Epoch 277/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6797 - accuracy: 0.3368\n",
            "Epoch 278/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6792 - accuracy: 0.3368\n",
            "Epoch 279/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6772 - accuracy: 0.3368\n",
            "Epoch 280/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6719 - accuracy: 0.3368\n",
            "Epoch 281/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.6727 - accuracy: 0.3368\n",
            "Epoch 282/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6682 - accuracy: 0.3368\n",
            "Epoch 283/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6762 - accuracy: 0.3570\n",
            "Epoch 284/490\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.6669 - accuracy: 0.3674\n",
            "Epoch 285/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6675 - accuracy: 0.3674\n",
            "Epoch 286/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6690 - accuracy: 0.3570\n",
            "Epoch 287/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6564 - accuracy: 0.3674\n",
            "Epoch 288/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6485 - accuracy: 0.3674\n",
            "Epoch 289/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6419 - accuracy: 0.3674\n",
            "Epoch 290/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6413 - accuracy: 0.3674\n",
            "Epoch 291/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6364 - accuracy: 0.3674\n",
            "Epoch 292/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6265 - accuracy: 0.3674\n",
            "Epoch 293/490\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.6293 - accuracy: 0.3570\n",
            "Epoch 294/490\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.6227 - accuracy: 0.3570\n",
            "Epoch 295/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.6067 - accuracy: 0.3674\n",
            "Epoch 296/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.6086 - accuracy: 0.3570\n",
            "Epoch 297/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6008 - accuracy: 0.3570\n",
            "Epoch 298/490\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.5844 - accuracy: 0.3674\n",
            "Epoch 299/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5826 - accuracy: 0.3674\n",
            "Epoch 300/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.5747 - accuracy: 0.3674\n",
            "Epoch 301/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5664 - accuracy: 0.3674\n",
            "Epoch 302/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.5630 - accuracy: 0.3674\n",
            "Epoch 303/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5573 - accuracy: 0.3674\n",
            "Epoch 304/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5530 - accuracy: 0.3674\n",
            "Epoch 305/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.5602 - accuracy: 0.3570\n",
            "Epoch 306/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.5536 - accuracy: 0.3570\n",
            "Epoch 307/490\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.5373 - accuracy: 0.3674\n",
            "Epoch 308/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.5389 - accuracy: 0.3368\n",
            "Epoch 309/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.5346 - accuracy: 0.3368\n",
            "Epoch 310/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.5384 - accuracy: 0.3264\n",
            "Epoch 311/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5209 - accuracy: 0.3674\n",
            "Epoch 312/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5276 - accuracy: 0.3570\n",
            "Epoch 313/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5148 - accuracy: 0.3674\n",
            "Epoch 314/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.5112 - accuracy: 0.3570\n",
            "Epoch 315/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4999 - accuracy: 0.3674\n",
            "Epoch 316/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5005 - accuracy: 0.3674\n",
            "Epoch 317/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4930 - accuracy: 0.3674\n",
            "Epoch 318/490\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.4984 - accuracy: 0.3570\n",
            "Epoch 319/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.4855 - accuracy: 0.3674\n",
            "Epoch 320/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4907 - accuracy: 0.3570\n",
            "Epoch 321/490\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.4781 - accuracy: 0.3674\n",
            "Epoch 322/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.4803 - accuracy: 0.3570\n",
            "Epoch 323/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4678 - accuracy: 0.3674\n",
            "Epoch 324/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4628 - accuracy: 0.3674\n",
            "Epoch 325/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4543 - accuracy: 0.3674\n",
            "Epoch 326/490\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.4545 - accuracy: 0.3674\n",
            "Epoch 327/490\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.4498 - accuracy: 0.3674\n",
            "Epoch 328/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4426 - accuracy: 0.3674\n",
            "Epoch 329/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4417 - accuracy: 0.3674\n",
            "Epoch 330/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4462 - accuracy: 0.3570\n",
            "Epoch 331/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4429 - accuracy: 0.3570\n",
            "Epoch 332/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4320 - accuracy: 0.3674\n",
            "Epoch 333/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4365 - accuracy: 0.3570\n",
            "Epoch 334/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4170 - accuracy: 0.3674\n",
            "Epoch 335/490\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1.4128 - accuracy: 0.3674\n",
            "Epoch 336/490\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.4223 - accuracy: 0.3570\n",
            "Epoch 337/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4041 - accuracy: 0.3674\n",
            "Epoch 338/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3979 - accuracy: 0.3980\n",
            "Epoch 339/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3935 - accuracy: 0.4287\n",
            "Epoch 340/490\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.3950 - accuracy: 0.4593\n",
            "Epoch 341/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3856 - accuracy: 0.4593\n",
            "Epoch 342/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3806 - accuracy: 0.4593\n",
            "Epoch 343/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.3760 - accuracy: 0.4593\n",
            "Epoch 344/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3771 - accuracy: 0.4593\n",
            "Epoch 345/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3718 - accuracy: 0.4593\n",
            "Epoch 346/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3646 - accuracy: 0.4593\n",
            "Epoch 347/490\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.3708 - accuracy: 0.4489\n",
            "Epoch 348/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3654 - accuracy: 0.4489\n",
            "Epoch 349/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3502 - accuracy: 0.4593\n",
            "Epoch 350/490\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.3493 - accuracy: 0.4489\n",
            "Epoch 351/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3439 - accuracy: 0.4489\n",
            "Epoch 352/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3325 - accuracy: 0.4593\n",
            "Epoch 353/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3301 - accuracy: 0.4593\n",
            "Epoch 354/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3267 - accuracy: 0.4593\n",
            "Epoch 355/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3208 - accuracy: 0.4593\n",
            "Epoch 356/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3266 - accuracy: 0.4489\n",
            "Epoch 357/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3145 - accuracy: 0.4489\n",
            "Epoch 358/490\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.3228 - accuracy: 0.4489\n",
            "Epoch 359/490\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.3166 - accuracy: 0.4489\n",
            "Epoch 360/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.3031 - accuracy: 0.4489\n",
            "Epoch 361/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3089 - accuracy: 0.4489\n",
            "Epoch 362/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.3060 - accuracy: 0.4795\n",
            "Epoch 363/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.2932 - accuracy: 0.4593\n",
            "Epoch 364/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2938 - accuracy: 0.4489\n",
            "Epoch 365/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2747 - accuracy: 0.4593\n",
            "Epoch 366/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2844 - accuracy: 0.4489\n",
            "Epoch 367/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2665 - accuracy: 0.4489\n",
            "Epoch 368/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2704 - accuracy: 0.4489\n",
            "Epoch 369/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2542 - accuracy: 0.4593\n",
            "Epoch 370/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2508 - accuracy: 0.4489\n",
            "Epoch 371/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2329 - accuracy: 0.4899\n",
            "Epoch 372/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2279 - accuracy: 0.4899\n",
            "Epoch 373/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2246 - accuracy: 0.4795\n",
            "Epoch 374/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2233 - accuracy: 0.5205\n",
            "Epoch 375/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2204 - accuracy: 0.5511\n",
            "Epoch 376/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2158 - accuracy: 0.6124\n",
            "Epoch 377/490\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.2150 - accuracy: 0.6124\n",
            "Epoch 378/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.2076 - accuracy: 0.6326\n",
            "Epoch 379/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.2063 - accuracy: 0.6430\n",
            "Epoch 380/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2060 - accuracy: 0.6326\n",
            "Epoch 381/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2041 - accuracy: 0.6326\n",
            "Epoch 382/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2008 - accuracy: 0.6326\n",
            "Epoch 383/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1986 - accuracy: 0.6430\n",
            "Epoch 384/490\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.1989 - accuracy: 0.6430\n",
            "Epoch 385/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2038 - accuracy: 0.6326\n",
            "Epoch 386/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1950 - accuracy: 0.6326\n",
            "Epoch 387/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1707 - accuracy: 0.6430\n",
            "Epoch 388/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1604 - accuracy: 0.6326\n",
            "Epoch 389/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1509 - accuracy: 0.6430\n",
            "Epoch 390/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1520 - accuracy: 0.6326\n",
            "Epoch 391/490\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.1338 - accuracy: 0.6430\n",
            "Epoch 392/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1358 - accuracy: 0.6326\n",
            "Epoch 393/490\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.1224 - accuracy: 0.6326\n",
            "Epoch 394/490\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.1129 - accuracy: 0.6430\n",
            "Epoch 395/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1109 - accuracy: 0.6326\n",
            "Epoch 396/490\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.1057 - accuracy: 0.6326\n",
            "Epoch 397/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1022 - accuracy: 0.6326\n",
            "Epoch 398/490\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.1080 - accuracy: 0.6326\n",
            "Epoch 399/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0922 - accuracy: 0.6632\n",
            "Epoch 400/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0958 - accuracy: 0.6632\n",
            "Epoch 401/490\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.0816 - accuracy: 0.6736\n",
            "Epoch 402/490\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.0863 - accuracy: 0.6632\n",
            "Epoch 403/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0711 - accuracy: 0.6736\n",
            "Epoch 404/490\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.0650 - accuracy: 0.6430\n",
            "Epoch 405/490\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.0673 - accuracy: 0.6632\n",
            "Epoch 406/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0544 - accuracy: 0.6736\n",
            "Epoch 407/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0490 - accuracy: 0.6430\n",
            "Epoch 408/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0428 - accuracy: 0.6430\n",
            "Epoch 409/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0483 - accuracy: 0.6326\n",
            "Epoch 410/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0289 - accuracy: 0.6430\n",
            "Epoch 411/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0346 - accuracy: 0.6326\n",
            "Epoch 412/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0179 - accuracy: 0.6326\n",
            "Epoch 413/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0116 - accuracy: 0.6430\n",
            "Epoch 414/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0087 - accuracy: 0.6326\n",
            "Epoch 415/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0143 - accuracy: 0.6632\n",
            "Epoch 416/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9996 - accuracy: 0.6938\n",
            "Epoch 417/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0079 - accuracy: 0.7857\n",
            "Epoch 418/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0003 - accuracy: 0.8163\n",
            "Epoch 419/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9953 - accuracy: 0.8163\n",
            "Epoch 420/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9832 - accuracy: 0.7244\n",
            "Epoch 421/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9818 - accuracy: 0.7244\n",
            "Epoch 422/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9753 - accuracy: 0.7348\n",
            "Epoch 423/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9680 - accuracy: 0.7244\n",
            "Epoch 424/490\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.9623 - accuracy: 0.7244\n",
            "Epoch 425/490\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.9532 - accuracy: 0.7655\n",
            "Epoch 426/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9491 - accuracy: 0.7348\n",
            "Epoch 427/490\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.9427 - accuracy: 0.7042\n",
            "Epoch 428/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9381 - accuracy: 0.7348\n",
            "Epoch 429/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9334 - accuracy: 0.7348\n",
            "Epoch 430/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.9323 - accuracy: 0.6938\n",
            "Epoch 431/490\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.9251 - accuracy: 0.7244\n",
            "Epoch 432/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9161 - accuracy: 0.8267\n",
            "Epoch 433/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9261 - accuracy: 0.8163\n",
            "Epoch 434/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9133 - accuracy: 0.7961\n",
            "Epoch 435/490\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.9076 - accuracy: 0.7961\n",
            "Epoch 436/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9155 - accuracy: 0.8469\n",
            "Epoch 437/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.9150 - accuracy: 0.9081\n",
            "Epoch 438/490\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9017 - accuracy: 0.8267\n",
            "Epoch 439/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9085 - accuracy: 0.8163\n",
            "Epoch 440/490\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.8925 - accuracy: 0.9081\n",
            "Epoch 441/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8975 - accuracy: 0.9081\n",
            "Epoch 442/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8850 - accuracy: 0.9694\n",
            "Epoch 443/490\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8802 - accuracy: 0.9388\n",
            "Epoch 444/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8708 - accuracy: 0.9388\n",
            "Epoch 445/490\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.8706 - accuracy: 0.9388\n",
            "Epoch 446/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8650 - accuracy: 0.9388\n",
            "Epoch 447/490\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8498 - accuracy: 0.9492\n",
            "Epoch 448/490\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8458 - accuracy: 0.9492\n",
            "Epoch 449/490\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8424 - accuracy: 0.9388\n",
            "Epoch 450/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8358 - accuracy: 0.9492\n",
            "Epoch 451/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8407 - accuracy: 0.9388\n",
            "Epoch 452/490\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8319 - accuracy: 0.9388\n",
            "Epoch 453/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8303 - accuracy: 0.9388\n",
            "Epoch 454/490\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.8184 - accuracy: 0.9388\n",
            "Epoch 455/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8154 - accuracy: 0.9388\n",
            "Epoch 456/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8182 - accuracy: 0.9388\n",
            "Epoch 457/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8045 - accuracy: 0.9388\n",
            "Epoch 458/490\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.8099 - accuracy: 0.9388\n",
            "Epoch 459/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7976 - accuracy: 0.9388\n",
            "Epoch 460/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8056 - accuracy: 0.9081\n",
            "Epoch 461/490\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.8049 - accuracy: 0.9081\n",
            "Epoch 462/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8006 - accuracy: 0.8775\n",
            "Epoch 463/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7991 - accuracy: 0.8469\n",
            "Epoch 464/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8017 - accuracy: 0.8469\n",
            "Epoch 465/490\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.7875 - accuracy: 0.8775\n",
            "Epoch 466/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7837 - accuracy: 0.8469\n",
            "Epoch 467/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7737 - accuracy: 0.8775\n",
            "Epoch 468/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7640 - accuracy: 0.9081\n",
            "Epoch 469/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7554 - accuracy: 0.9186\n",
            "Epoch 470/490\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7553 - accuracy: 0.9388\n",
            "Epoch 471/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7529 - accuracy: 0.9388\n",
            "Epoch 472/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7421 - accuracy: 0.9388\n",
            "Epoch 473/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7392 - accuracy: 0.9388\n",
            "Epoch 474/490\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.7349 - accuracy: 0.9388\n",
            "Epoch 475/490\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7436 - accuracy: 0.9388\n",
            "Epoch 476/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7339 - accuracy: 0.9388\n",
            "Epoch 477/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7384 - accuracy: 0.9388\n",
            "Epoch 478/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7234 - accuracy: 0.9388\n",
            "Epoch 479/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7194 - accuracy: 0.9388\n",
            "Epoch 480/490\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.7174 - accuracy: 0.9388\n",
            "Epoch 481/490\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7229 - accuracy: 0.9388\n",
            "Epoch 482/490\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7201 - accuracy: 0.9388\n",
            "Epoch 483/490\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7186 - accuracy: 0.8775\n",
            "Epoch 484/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7000 - accuracy: 0.8879\n",
            "Epoch 485/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7052 - accuracy: 0.8775\n",
            "Epoch 486/490\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6966 - accuracy: 0.9388\n",
            "Epoch 487/490\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6869 - accuracy: 0.9388\n",
            "Epoch 488/490\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6918 - accuracy: 0.9388\n",
            "Epoch 489/490\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6793 - accuracy: 0.9388\n",
            "Epoch 490/490\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6715 - accuracy: 0.9388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMDagg5B7JqT"
      },
      "source": [
        "최종 loss: 0.6715 - accuracy: 0.9388\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpFkzqoJ7SE6",
        "outputId": "f3da4f76-7357-4f4a-ffd4-76cb0f775a22"
      },
      "source": [
        "# to save the trained model\r\n",
        "model.save(\"JW_model_2\")\r\n",
        "\r\n",
        "import pickle\r\n",
        "\r\n",
        "# to save the fitted tokenizer\r\n",
        "with open('tokenizer.pickle', 'wb') as handle:\r\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\r\n",
        "    \r\n",
        "# to save the fitted label encoder\r\n",
        "with open('label_encoder.pickle', 'wb') as ecn_file:\r\n",
        "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: JW_model_2/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayoD19Lt8KK8"
      },
      "source": [
        "pip install colorama\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "id": "5A-disAv77PR",
        "outputId": "3ce96462-ad90-4dde-ec8d-0b527a61e00b"
      },
      "source": [
        "\r\n",
        "import json \r\n",
        "import numpy as np\r\n",
        "from tensorflow import keras\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "\r\n",
        "import colorama \r\n",
        "colorama.init()\r\n",
        "from colorama import Fore, Style, Back\r\n",
        "\r\n",
        "import random\r\n",
        "import pickle\r\n",
        "\r\n",
        "with open(\"intents.json\") as file:\r\n",
        "    data = json.load(file)\r\n",
        "\r\n",
        "\r\n",
        "def chat():\r\n",
        "    # load trained model\r\n",
        "    model = keras.models.load_model('chat_model')\r\n",
        "\r\n",
        "    # load tokenizer object\r\n",
        "    with open('tokenizer.pickle', 'rb') as handle:\r\n",
        "        tokenizer = pickle.load(handle)\r\n",
        "\r\n",
        "    # load label encoder object\r\n",
        "    with open('label_encoder.pickle', 'rb') as enc:\r\n",
        "        lbl_encoder = pickle.load(enc)\r\n",
        "\r\n",
        "    # parameters\r\n",
        "    max_len = 20\r\n",
        "    \r\n",
        "    while True:\r\n",
        "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\r\n",
        "        inp = input()\r\n",
        "        if inp.lower() == \"quit\":\r\n",
        "            break\r\n",
        "\r\n",
        "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\r\n",
        "                                             truncating='post', maxlen=max_len))\r\n",
        "        #print('result : ',result)\r\n",
        "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\r\n",
        "        #print('tag : ',tag)\r\n",
        "\r\n",
        "        for i in data['intents']:\r\n",
        "            if i['tag'] == tag:\r\n",
        "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\r\n",
        "\r\n",
        "        # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\r\n",
        "\r\n",
        "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\r\n",
        "chat()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start messaging with the bot (type quit to stop)!\n",
            "User: Hi\n",
            "WARNING:tensorflow:7 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa75cdfcd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "result :  [[0.03010814 0.01078339 0.03460111 0.08598869 0.6074504  0.00819192\n",
            "  0.0414453  0.18143098]]\n",
            "tag :  ['greeting']\n",
            "ChatBot: Hi there\n",
            "User: Who are you?\n",
            "result :  [[0.2224784  0.00356181 0.00604405 0.17680888 0.2193965  0.00768735\n",
            "  0.31941083 0.04461214]]\n",
            "tag :  ['name']\n",
            "ChatBot: You can call me Joana.\n",
            "User: What are you?\n",
            "result :  [[0.21921374 0.00356596 0.00594932 0.17610598 0.21728979 0.00751528\n",
            "  0.32617855 0.04418132]]\n",
            "tag :  ['name']\n",
            "ChatBot: I'm Joana!\n",
            "User: "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-cfffc5f24074>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYELLOW\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Start messaging with the bot (type quit to stop)!\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mStyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESET_ALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-62-cfffc5f24074>\u001b[0m in \u001b[0;36mchat\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLIGHTBLUE_EX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"User: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mStyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESET_ALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFdZteup8Yoy"
      },
      "source": [
        "for i in data['intents']:\r\n",
        "  print(i['tag'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CaVC7Zs899q0",
        "outputId": "5e912bd2-5ea9-46cd-869f-b4da41d7ba2e"
      },
      "source": [
        "labels[5]\r\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'help'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwpMYasDCcvh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}